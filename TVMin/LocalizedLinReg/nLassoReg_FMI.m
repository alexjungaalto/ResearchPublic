%%%%
% script for generating the Figure 2 in the paper Localized Linear
% "Regression in Networked Data"
%%%%%%
%%
% 1. the FMI measurements are read in from a csv file 'obs.csv'
% 2. the empirical graph (nodes="FMI station") is constructed by connecting 
%    each node with the K=??? nearst neighbours 
% 3. each node is assigned a feature vector consisting of the average
% temperature from the last d=??? days
% 4. run nLasso

clear all
close all
%%%% Generate two separate ER graphs of size N/2 with edge probability p
%%%% connect nodes between two cluter ERs using edge probability q
restoredefaultpath
rehash toolboxcache

[pathtothismfile,name,ext] = fileparts(mfilename('fullpath')) ; 


%% Import data from text file.
% Script for importing data from the following text file:
%
%    /Users/alexanderjung/Dropbox (Aalto)/nlassoregression/obs.csv
%
% To extend the code to different selected data or a different text file,
% generate a function instead of a script.

% Auto-generated by MATLAB on 2019/05/11 20:57:35

%% Initialize variables.
%filename = '/Users/alexanderjung/Dropbox (Aalto)/nlassoregression/obs.csv';
filename = 'obs.csv' ;
delimiter = ';';
startRow = 2;

%% Format for each line of text:
%   column1: double (%f)
%	column2: double (%f)
%   column3: double (%f)
%	column4: double (%f)
%   column5: double (%f)
%	column6: double (%f)
%   column7: double (%f)
%	column8: double (%f)
%   column9: double (%f)
%	column10: categorical (%C)
%   column11: categorical (%C)
%	column12: categorical (%C)
%   column13: double (%f)
%	column14: double (%f)
%   column15: double (%f)
%	column16: double (%f)
% For more information, see the TEXTSCAN documentation.
formatSpec = '%f%f%f%f%f%f%f%f%f%C%C%C%f%f%f%f%[^\n\r]';

%% Open the text file.
fileID = fopen(filename,'r');

%% Read columns of data according to the format.
% This call is based on the structure of the file used to generate this
% code. If an error occurs for a different file, try regenerating the code
% from the Import Tool.
dataArray = textscan(fileID, formatSpec, 'Delimiter', delimiter, 'TextType', 'string', 'EmptyValue', NaN, 'HeaderLines' ,startRow-1, 'ReturnOnError', false, 'EndOfLine', '\r\n');

%% Close the text file.
fclose(fileID);

%% Post processing for unimportable data.
% No unimportable data rules were applied during the import, so no post
% processing code is included. To generate code which works for
% unimportable data, select unimportable cells in a file and regenerate the
% script.

%% Create output variable
obs1 = table(dataArray{1:end-1}, 'VariableNames', {'lat','lon','timestamp','temp','Windspeedws_10min','Gustspeedwg_10min','Winddirectionwd_10min','Relativehumidityrh','Dewpointtemperaturetd','Precipitationamountr_1h','Precipitationintensityri_10min','Snowdepthsnow_aws','Pressuremslp_sea','Horizontalvisibilityvis','Cloudamountn_man','Presentweatherautowawa'});

%% Clear temporary variables
clearvars filename delimiter startRow formatSpec fileID dataArray ans;

obs1=rmmissing(obs1) ; 
[dmy,obs_idx_row]= unique(obs1.lat) ; 

stat_lat = obs1.lat(obs_idx_row) ; 
stat_lon = obs1.lon(obs_idx_row) ; 


cluster_1 = [38,36,33,22,23,28,20,18,15,13,12,17,7,9,5,2,3] ; 
cluster_2 = [1,4,16,6,8,10,19,26,27,29,30,32,35,37,44,45,51,50,47]; 
cluster_3 = [23,18,22,15,12,13,9,7,5]; 
cluster_4 = [23,18,22,15,12,13,9,7,5,28,20,17,2,3]; 

FMI_stations = [stat_lat stat_lon]; 
nr_stations = length(stat_lat) ; 
N=nr_stations ; 


%%%%%%%%%%%%
% here we create the links between neighboring FMI stations
K_nn=3 ; 
Idx = knnsearch(FMI_stations,FMI_stations,'K',K_nn+1) ; 
A = zeros(nr_stations,nr_stations) ; 

for iter_obs=1:nr_stations 
    A(iter_obs,Idx(iter_obs,:)) = 1 ; 
end
% A(23,20)=1 ; 
% A(3,12)=1 ; 
% A(17,12)=1 ; 
% A(3,7)=1 ; 
A = (A+A') ; 
A(A>0.1)= 1 ; 
A = A-eye(size(A)); 

G = graph(A,'upper'); 

%%%%%%%%%%%%
% indicate FMI weather stations by circles 
geoplot(FMI_stations(:,1),FMI_stations(:,2),'o','MarkerSize',10,'LineWidth',2); 
hold on; 
% indicate Helsinki with red cross
geoplot(60.192,24.9458,'rx','MarkerSize',20,'LineWidth',5);


measurements = zeros(1,nr_stations); 
for iter_station=1:nr_stations 
    label = sprintf('%3d',iter_station) ; 
    text(FMI_stations(iter_station,1),FMI_stations(iter_station,2),label,'FontSize',20);
end

% number of features at each data point 
d=3; 

X_mtx = zeros(d,N) ; 
true_y = zeros(1,N) ; 

for iter_station=1:nr_stations 
    
    idx_station = find ((obs1.lat - FMI_stations(iter_station,1)).^2+ (obs1.lon - FMI_stations(iter_station,2)).^2 < 0.0001 ) ; 
    dmy = obs1.temp(idx_station) ;
    indices = find(isnan(dmy) == 0);
    
    blocklen=floor(length(indices)/(d+1)) ; 
    
    for iter_dim=1:d
     X_mtx(iter_dim,iter_station) = sum(dmy(indices(((iter_dim-1)*blocklen+1):(blocklen*iter_dim))))/blocklen ; 
    end
    true_y(1,iter_station) = sum(dmy(indices(((d)*blocklen+1):(blocklen*(d+1)))))/blocklen ;
    idxs = find(A(iter_station,:)>0.1) ;
    
    
     % draw links between each FMI station and its d nearest neighbours (NN) 
     
     for iter_inner=1:length(idxs) 
       geoplot(FMI_stations([iter_station,idxs(iter_inner)],1),FMI_stations([iter_station,idxs(iter_inner)],2),'k-','LineWidth',1)
     end
   
  
end


 nr_nodes = N ; 
 feature_dim= d ; 
 
 feature_mtx = X_mtx; 
 
 mask_mtx =kron(eye(nr_nodes,nr_nodes),ones(feature_dim,feature_dim)) ;
 feature_norm_squared_vec = sum(feature_mtx.^2,1) ; 
 norm_features_2 = kron(diag((feature_norm_squared_vec)),eye(feature_dim,feature_dim)) ; 
 feature_mtx_vec= reshape(feature_mtx,nr_nodes*feature_dim,1); 
 proj_feature = ((feature_mtx_vec*feature_mtx_vec').*mask_mtx)*inv(norm_features_2);
 
 out_of_proj =  (eye(nr_nodes*feature_dim,nr_nodes*feature_dim)-proj_feature) ; 


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Graph Initialisation SBM
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Intra-edge probability of a cluster:
%p = .1;
% Inter-edge probability between clusters
%q = 0.99;



% Number of nodes per cluster
%N1 = 40;
%N2 = 40;
% total number of nodes 
%N=N1+N2;






%G = zeros(N,N) ;





%for iter_boundary=1:length(boundary_size_values)
%    boundary_edges = boundary_size_values(iter_boundary); 

    %boundary_edges = 12; 

    %%%%% 
% generate feature vectors for each data point 
%%%%%


%X_mtx = X_mtx*inv(diag(sqrt(diag(X_mtx'*X_mtx)))) ; 
    
    
%triu(G_SBM,1) ;

% define training set and true graph signal 
%graphsig = 0.1*[ones(N1,1);-1*ones(N2,1)] ;

y   = true_y' ; 

%samplingset = [1:3 (N-2):N]; 
%dmy = (1:N); 


% %% determine flow from sampled node 1 to boundary between first 
% %% N1 nodes and second N2 nodes 
% 
% G1 = G_SBM; 
% G1(1:N1,(N1+1):N) = 2*G1(1:N1,(N1+1):N) ; 
% G1((N1+1):N,(N1+1):N) = (10^3) *ones(N2,N2) ;
% %G1(1:N1,1:N1) = (10^10) *ones(N1,N1) ;
% G1 = triu(G1,1); 
% G1 = G1+G1' ; 
% 
% %%flowgraph1(((N1+1):N):((N1+1):N)) = 10^10*ones( ; 
%  flowgraph = digraph(G1); 
%  flowsamplednodes=maxflow(flowgraph,1,N) ;
%  flow_boundary=sum(sum(G_SBM(1:N1,(N1+1):N))) ; 
%  
%  if (flow_boundary < 1) 
%      flow_boundary = 1 ; 
%  end
%  
%  ratio_bound_flow(iter_boundary,iter_RUNS) = flowsamplednodes/flow_boundary ; 
%  
% % %samplingset = [samplingnode1 samplingnode2]; 
% 
% 
% 
% 
% %plot(nodes(samplingset,1),nodes(samplingset,2),'cx','Color',[1,0,0])
% 
% 
% % for iter_node=1:N 
% %     for iter_node1=1:iter_node 
% %         
% %         if G(iter_node,iter_node1) >0
% %             plot([nodes(iter_node,1) nodes(iter_node1,1)],[nodes(iter_node,2) nodes(iter_node1,2)],'ro')
% % 
% %            hline = gline; % Connect circles
% %             set(hline,'Color','r')
% %         end
% %     end
% % end
% 
% %D = triu(G); 

Adjac = triu(A,1) ; 
A_undirected = Adjac+Adjac' ; 
degrees = sum(A_undirected,1); 
inv_degrees = 1./degrees';

%%%% create weighted incidence matrix 
G = digraph(triu(A,1)) ;
D = sparse(incidence(G)') ;
D_block= kron(D,eye(d,d)) ; 

[nr_edges, N] = size(D); 
edge_weights = zeros(nr_edges,1); 
%for iter_edge=1:M
%    [s,t] = findedge(G,iter_edge); %finds the source and target nodes of the edges specified by idx.
%     edge_weights(iter_edge) = sqrt(A_undirected(s,t)) ; 
%end
%D = diag(edge_weights)*D ; 

%%%%% some visio

%scatter(nodes(:,1),nodes(:,2)) ; 
%figure(1);
%plot(G);   
%hold on 

Lambda = diag((1./(sum(abs(D),2)))) ; 
Lambda_block = kron(Lambda,eye(d,d)) ;
Gamma_vec=(1./(sum(abs(D),1)))' ;
Gamma = diag(Gamma_vec);  
Gamma_block = kron(Gamma,eye(d,d)) ; 


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Algorithm Initialisation
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


primSLP = ones(N,1); 
primSLp(N) = 0 ; 
%running_average;
dualSLP =(1:(N-1))'/(N-1) ; %running_averagey; 
dualSLP = zeros(nr_edges,1); 


hatx = zeros(N,1); 


lambda =1/10 ; 
lambda = 1/9;
lambda = 1/7; 


RUNS = 1; 
MSE = zeros(RUNS,1); 
for iter_runs=1:RUNS 
    
dmy_idx = ones(N,1); 
dmy_idx(cluster_3) = 0 ; 
dmy_idx([12,13,15]) = 1 ; 
samplingset = find(dmy_idx >0.2) ; 
unlabeled = find(dmy_idx <0.2); 

hatx = zeros(N*d,1); 
running_average =zeros(N*d,1);
%haty = ((1:(N-1))/(N-1))'; 
haty = zeros(nr_edges*d,1); 
running_averagey = zeros(nr_edges*d,1); 
hatxLP = zeros(N*d,1); 
hatw = zeros(d*N,1) ; 


%log_conv=zeros(N,1); 
%log_bound=zeros(N,1); 

for iterk=1:10000
    
  % LP iteration 
  %  hatxLP = inv_degrees.*(A_undirected*hatxLP); 
  %  hatxLP(samplingset) = graphsig(samplingset); 
    
    % SLP iteration
    newx = hatx - 0.5*Gamma_block*(D_block'*haty) ; 
    newx = block_thresholding(newx,samplingset,y,X_mtx,d,N,Gamma_vec,out_of_proj,feature_norm_squared_vec) ; 
    %newx(samplingset) = graphsig(samplingset) ; 
    tildex = 2*newx-hatx; 
    newy = haty + 0.5*Lambda_block*(D_block*tildex); 
    haty = block_clipping(newy,d,nr_edges,lambda)  ;
    hatx = newx; 
    running_average = (running_average*(iterk-1) +hatx)/iterk; 
    
    
    %running_averagey = (running_average*(iterk-1) +haty)/iterk;+
    %  dual = sign(D*running_average); 
    % dual(iterk:(N-1)) = 0 ;
    % log_conv(iterk) = sum(abs(D*running_average)); 
    % log_bound(iterk) =(1/(2*iterk))*(primSLP'*inv(Gamma)*primSLP)+((dualSLP-dual)'*inv(Lambda)*(dualSLP-dual)) ;
end




%figure(1); 
%stem(primSLP);
%title('primal SLP')
%figure(2); 
%stem(dualSLP); 
%title('dual SLP')
%figure(2); 
w_hat=reshape(running_average,d,N) ; 

%norm_w_hat=sum(w_hat.^2,1); 

y_hat = sum(X_mtx.*w_hat) ; 
%stem([y_hat' true_y']); 

MSE(iter_runs)=norm(y_hat(unlabeled)-true_y(unlabeled),2)^2 / norm (true_y(unlabeled),2)^2 ; 
end

figure(3); 
mtx = reshape(running_average,d,N)'; 
stem(mtx(unlabeled,:)); 

A_mtx = feature_mtx(:,unlabeled) ;
A_mtx =A_mtx';
y = true_y(unlabeled) ;
y = y';
[x,dmy] = lad (A_mtx,y,1,1);
norm(A_mtx*x -y,2)^2 / norm(y,2)^2



%T = array2table(mtx,'VariableNames',{'a','b'});
%filename = sprintf('MSE_FMI_%s.csv',date) ;
%writetable(T,fullfile(pathtothismfile,filename));


%figure(4); 
%stem(dual);
%bound =log_bound+(1./(2*(1:K))*(hatx'*inv(Lambda)*hatx) ; 
%plot(1:N,log([log_conv log_bound])); 


function weights_out = block_clipping (weights_in,feature_dim,nr_edges,lambda) 
%%% input: weights_in vector of length featuredim*nr_datapoints, scalar
%%% lambda 
 mtx = reshape(weights_in,feature_dim,nr_edges);
 x_norm = sqrt(sum(mtx.^2,1)) ; 

 
 idx_exceed = find(x_norm>lambda) ; 
 factor = ones(1,nr_edges); 
 
 for iter_idx=1:length(idx_exceed) 
     idx = idx_exceed(iter_idx) ; 
     factor(idx) = lambda./x_norm(idx); 
 end
 
 
 %factor = max([x_norm;lambda*ones(1,nr_edges)],[],1) ;  
 weights_out= mtx*diag(factor);
 
 weights_out = reshape(weights_out,feature_dim*nr_edges,1) ; 
 


end 

function weights_out = block_thresholding (weights_in,sampling_set,y,feature_mtx,feature_dim,nr_nodes,tau_vec,out_of_proj,feature_norm_squared_vec) 
%%% input: weights_in vector of length featuredim*nr_datapoints, scalar
%%% lambda 
 
%  mask_sampling_set = zeros(1,nr_nodes); 
%  mask_sampling_set(sampling_set) = 1 ; 
%  mask_sampling_set= ones(feature_dim,1)*mask_sampling_set; 
%  

%  mask_mtx =kron(eye(nr_nodes,nr_nodes),ones(feature_dim,feature_dim)) ;
%  
%  feature_norm_squared_vec = sum(feature_mtx.^2,1) ; 
%  
%  norm_features_2 = kron(diag((feature_norm_squared_vec)),eye(feature_dim,feature_dim)) ; 
%  
%  feature_mtx_vec= reshape(feature_mtx,nr_nodes*feature_dim,1); 
%  
%  proj_feature = ((feature_mtx_vec*feature_mtx_vec').*mask_mtx)*inv(norm_features_2);
 
 %%%% project input weight vector on orthogonal complement of feature
 %%%% vector space 
 
 out_of_feature = out_of_proj*weights_in ; 
 
 %%%% compute coefficient for input weights on feature direction input
 
 weights_in_row = reshape(weights_in,feature_dim,nr_nodes); 
 
 weights_in_coeff = sum(feature_mtx.*weights_in_row,1)./feature_norm_squared_vec ; 
 
 coeffs = zeros(nr_nodes,1); 
 
 %coeffs(sampling_set) = y(sampling_set)./norm_sqared_features(sampling_set) ;
 
 for iter_node=1:length(sampling_set) 
    node_idx = sampling_set(iter_node); 
    dmy = weights_in_coeff(node_idx) - (y(node_idx)/feature_norm_squared_vec(node_idx)) ; 
    dmy = wthresh(dmy,'s',tau_vec(node_idx)) ; 
    coeffs (node_idx) = (y(node_idx)/feature_norm_squared_vec(node_idx))+dmy; 
 end  
 
 
 %mtx_w = reshape(weights_in,feature_dim,nr_nodes);
 
 
%  component1 = zeros(size(mtx_w)) ; 
%  component2 = zeros(size(mtx_w)) ; 
%  
%  mtx_x = feature_mtx; 
%  
%  tau_vec = reshape(tau_vec,nr_nodes,1); 
%  tau_mtx = ones(feature_dim,1)*tau_vec'; 
 
%  y_hat = sum(mtx_w.*mtx_x,1) ; 
%  y     = reshape(y,1,nr_nodes); 
%  
%  
%  x_norm = sum(mtx_x.^2,1).*tau_vec' ;
%  
%  index_vec = find(y > (y_hat + x_norm)); 
%  
%  dmy = (mtx_x.*tau_mtx).*mask_sampling_set ; 
%  
%  component1(:,index_vec) = dmy(:,index_vec) ; 
%  
%  index_vec = find(y < (y_hat + x_norm)); 
%  
%  dmy = - (mtx_x.*tau_mtx).*mask_sampling_set ; 
%  component2(:,index_vec) = dmy(:,index_vec) ; 
%  
%  mtx_w = mtx_w + component1+component2; 
%  
 
 tmp = feature_mtx*diag(coeffs) + reshape(out_of_feature,feature_dim,nr_nodes); 

 weights_out = reshape(weights_in,feature_dim,nr_nodes) ; 
 weights_out(:,sampling_set) = tmp(:,sampling_set); 
 weights_out = reshape(weights_out,feature_dim*nr_nodes,1) ; 
 
end 


